"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[248],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>h});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function l(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?l(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},d=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},m=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),u=p(t),m=r,h=u["".concat(s,".").concat(m)]||u[m]||c[m]||l;return t?a.createElement(h,i(i({ref:n},d),{},{components:t})):a.createElement(h,i({ref:n},d))}));function h(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var l=t.length,i=new Array(l);i[0]=m;var o={};for(var s in n)hasOwnProperty.call(n,s)&&(o[s]=n[s]);o.originalType=e,o[u]="string"==typeof e?e:r,i[1]=o;for(var p=2;p<l;p++)i[p]=t[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},2137:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>c,frontMatter:()=>l,metadata:()=>o,toc:()=>p});var a=t(7462),r=(t(7294),t(3905));const l={},i=void 0,o={unversionedId:"BuildModel",id:"BuildModel",title:"BuildModel",description:"Learn the Basics ||",source:"@site/docs/06-BuildModel.md",sourceDirName:".",slug:"/BuildModel",permalink:"/pytorch-basics/docs/BuildModel",draft:!1,tags:[],version:"current",sidebarPosition:6,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Transforms",permalink:"/pytorch-basics/docs/Transforms"},next:{title:"Autograd",permalink:"/pytorch-basics/docs/Autograd"}},s={},p=[{value:"Get Device for Training",id:"get-device-for-training",level:2},{value:"Define the Class",id:"define-the-class",level:2},{value:"Model Layers",id:"model-layers",level:2},{value:"nn.Flatten",id:"nnflatten",level:3},{value:"nn.Linear",id:"nnlinear",level:3},{value:"nn.ReLU",id:"nnrelu",level:3},{value:"nn.Sequential",id:"nnsequential",level:3},{value:"nn.Softmax",id:"nnsoftmax",level:3},{value:"Model Parameters",id:"model-parameters",level:2},{value:"Further Reading",id:"further-reading",level:2}],d={toc:p},u="wrapper";function c(e){let{components:n,...t}=e;return(0,r.kt)(u,(0,a.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"intro.html"},"Learn the Basics")," ||\n",(0,r.kt)("a",{parentName:"p",href:"quickstart_tutorial.html"},"Quickstart")," ||\n",(0,r.kt)("a",{parentName:"p",href:"tensorqs_tutorial.html"},"Tensors")," ||\n",(0,r.kt)("a",{parentName:"p",href:"data_tutorial.html"},"Datasets & DataLoaders")," ||\n",(0,r.kt)("a",{parentName:"p",href:"transforms_tutorial.html"},"Transforms")," ||\n",(0,r.kt)("strong",{parentName:"p"},"Build Model")," ||\n",(0,r.kt)("a",{parentName:"p",href:"autogradqs_tutorial.html"},"Autograd")," ||\n",(0,r.kt)("a",{parentName:"p",href:"optimization_tutorial.html"},"Optimization")," ||\n",(0,r.kt)("a",{parentName:"p",href:"saveloadrun_tutorial.html"},"Save & Load Model")),(0,r.kt)("h1",{id:"build-the-neural-network"},"Build the Neural Network"),(0,r.kt)("p",null,"Neural networks comprise of layers/modules that perform operations on data.\nThe ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/nn.html"},"torch.nn")," namespace provides all the building blocks you need to\nbuild your own neural network. Every module in PyTorch subclasses the ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Module.html"},"nn.Module"),".\nA neural network is a module itself that consists of other modules (layers). This nested structure allows for\nbuilding and managing complex architectures easily."),(0,r.kt)("p",null,"In the following sections, we'll build a neural network to classify images in the FashionMNIST dataset."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"%matplotlib inline\n\nimport os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n")),(0,r.kt)("h2",{id:"get-device-for-training"},"Get Device for Training"),(0,r.kt)("p",null,"We want to be able to train our model on a hardware accelerator like the GPU,\nif it is available. Let's check to see if\n",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/notes/cuda.html"},"torch.cuda")," is available, else we\ncontinue to use the CPU."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'device = "cuda" if torch.cuda.is_available() else "cpu"\nprint(f"Using {device} device")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Using cpu device\n")),(0,r.kt)("h2",{id:"define-the-class"},"Define the Class"),(0,r.kt)("p",null,"We define our neural network by subclassing ",(0,r.kt)("inlineCode",{parentName:"p"},"nn.Module"),", and\ninitialize the neural network layers in ",(0,r.kt)("inlineCode",{parentName:"p"},"__init__"),". Every ",(0,r.kt)("inlineCode",{parentName:"p"},"nn.Module")," subclass implements\nthe operations on input data in the ",(0,r.kt)("inlineCode",{parentName:"p"},"forward")," method."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"class NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n")),(0,r.kt)("p",null,"We create an instance of ",(0,r.kt)("inlineCode",{parentName:"p"},"NeuralNetwork"),", and move it to the ",(0,r.kt)("inlineCode",{parentName:"p"},"device"),", and print\nits structure."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"model = NeuralNetwork().to(device)\nprint(model)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"NeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n")),(0,r.kt)("p",null,"To use the model, we pass it the input data. This executes the model's ",(0,r.kt)("inlineCode",{parentName:"p"},"forward"),",\nalong with some ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866"},"background operations"),".\nDo not call ",(0,r.kt)("inlineCode",{parentName:"p"},"model.forward()")," directly!"),(0,r.kt)("p",null,"Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output.\nWe get the prediction probabilities by passing it through an instance of the ",(0,r.kt)("inlineCode",{parentName:"p"},"nn.Softmax")," module."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'X = torch.rand(1, 28, 28, device=device)\nlogits = model(X)\npred_probab = nn.Softmax(dim=1)(logits)\ny_pred = pred_probab.argmax(1)\nprint(f"Predicted class: {y_pred}")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Predicted class: tensor([1])\n")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"model-layers"},"Model Layers"),(0,r.kt)("p",null,"Let's break down the layers in the FashionMNIST model. To illustrate it, we\nwill take a sample minibatch of 3 images of size 28x28 and see what happens to it as\nwe pass it through the network."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"input_image = torch.rand(3,28,28)\nprint(input_image.size())\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"torch.Size([3, 28, 28])\n")),(0,r.kt)("h3",{id:"nnflatten"},"nn.Flatten"),(0,r.kt)("p",null,"We initialize the ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html"},"nn.Flatten"),"\nlayer to convert each 2D 28x28 image into a contiguous array of 784 pixel values (\nthe minibatch dimension (at dim=0) is maintained)."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"flatten = nn.Flatten()\nflat_image = flatten(input_image)\nprint(flat_image.size())\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"torch.Size([3, 784])\n")),(0,r.kt)("h3",{id:"nnlinear"},"nn.Linear"),(0,r.kt)("p",null,"The ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"},"linear layer"),"\nis a module that applies a linear transformation on the input using its stored weights and biases."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"layer1 = nn.Linear(in_features=28*28, out_features=20)\nhidden1 = layer1(flat_image)\nprint(hidden1.size())\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"torch.Size([3, 20])\n")),(0,r.kt)("h3",{id:"nnrelu"},"nn.ReLU"),(0,r.kt)("p",null,"Non-linear activations are what create the complex mappings between the model's inputs and outputs.\nThey are applied after linear transformations to introduce ",(0,r.kt)("em",{parentName:"p"},"nonlinearity"),", helping neural networks\nlearn a wide variety of phenomena."),(0,r.kt)("p",null,"In this model, we use ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html"},"nn.ReLU")," between our\nlinear layers, but there's other activations to introduce non-linearity in your model."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'print(f"Before ReLU: {hidden1}\\n\\n")\nhidden1 = nn.ReLU()(hidden1)\nprint(f"After ReLU: {hidden1}")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Before ReLU: tensor([[-0.0330, -0.3102,  0.1676, -0.1933, -0.2567, -0.1062, -0.0066,  0.2878,\n         -0.2589,  0.4172, -0.1073,  0.3151, -0.0417,  0.3633, -0.4007,  0.2303,\n         -0.4934, -0.1298, -0.5092,  0.0009],\n        [-0.1326, -0.0833, -0.2520, -0.1601, -0.4922,  0.2142,  0.0159,  0.1273,\n         -0.2728,  0.7323, -0.0243,  0.1356, -0.1572,  0.5686, -0.4338,  0.3796,\n         -0.3577,  0.1426, -0.4462, -0.0726],\n        [ 0.0095, -0.0641,  0.1023, -0.0185, -0.7594, -0.3129, -0.0486,  0.2032,\n         -0.1019,  0.2325,  0.0089,  0.1495, -0.0415,  0.3710, -0.3772,  0.2013,\n         -0.3452, -0.1642, -0.2741, -0.0379]], grad_fn=<AddmmBackward0>)\n\n\nAfter ReLU: tensor([[0.0000, 0.0000, 0.1676, 0.0000, 0.0000, 0.0000, 0.0000, 0.2878, 0.0000,\n         0.4172, 0.0000, 0.3151, 0.0000, 0.3633, 0.0000, 0.2303, 0.0000, 0.0000,\n         0.0000, 0.0009],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2142, 0.0159, 0.1273, 0.0000,\n         0.7323, 0.0000, 0.1356, 0.0000, 0.5686, 0.0000, 0.3796, 0.0000, 0.1426,\n         0.0000, 0.0000],\n        [0.0095, 0.0000, 0.1023, 0.0000, 0.0000, 0.0000, 0.0000, 0.2032, 0.0000,\n         0.2325, 0.0089, 0.1495, 0.0000, 0.3710, 0.0000, 0.2013, 0.0000, 0.0000,\n         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n")),(0,r.kt)("h3",{id:"nnsequential"},"nn.Sequential"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html"},"nn.Sequential")," is an ordered\ncontainer of modules. The data is passed through all the modules in the same order as defined. You can use\nsequential containers to put together a quick network like ",(0,r.kt)("inlineCode",{parentName:"p"},"seq_modules"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"seq_modules = nn.Sequential(\n    flatten,\n    layer1,\n    nn.ReLU(),\n    nn.Linear(20, 10)\n)\ninput_image = torch.rand(3,28,28)\nlogits = seq_modules(input_image)\n")),(0,r.kt)("h3",{id:"nnsoftmax"},"nn.Softmax"),(0,r.kt)("p",null,"The last linear layer of the neural network returns ",(0,r.kt)("inlineCode",{parentName:"p"},"logits")," - raw values in ","[-\\infty, \\infty]"," - which are passed to the\n",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html"},"nn.Softmax")," module. The logits are scaled to values\n","[0, 1]"," representing the model's predicted probabilities for each class. ",(0,r.kt)("inlineCode",{parentName:"p"},"dim")," parameter indicates the dimension along\nwhich the values must sum to 1."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"softmax = nn.Softmax(dim=1)\npred_probab = softmax(logits)\n")),(0,r.kt)("h2",{id:"model-parameters"},"Model Parameters"),(0,r.kt)("p",null,"Many layers inside a neural network are ",(0,r.kt)("em",{parentName:"p"},"parameterized"),", i.e. have associated weights\nand biases that are optimized during training. Subclassing ",(0,r.kt)("inlineCode",{parentName:"p"},"nn.Module")," automatically\ntracks all fields defined inside your model object, and makes all parameters\naccessible using your model's ",(0,r.kt)("inlineCode",{parentName:"p"},"parameters()")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"named_parameters()")," methods."),(0,r.kt)("p",null,"In this example, we iterate over each parameter, and print its size and a preview of its values."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'print(f"Model structure: {model}\\n\\n")\n\nfor name, param in model.named_parameters():\n    print(f"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Model structure: NeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n\n\nLayer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0038,  0.0141, -0.0139,  ...,  0.0199,  0.0147,  0.0348],\n        [ 0.0244, -0.0097,  0.0065,  ...,  0.0176, -0.0098,  0.0025]],\n       grad_fn=<SliceBackward0>) \n\nLayer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0056, -0.0259], grad_fn=<SliceBackward0>) \n\nLayer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0150,  0.0164,  0.0198,  ...,  0.0220,  0.0428,  0.0442],\n        [ 0.0065, -0.0132, -0.0128,  ...,  0.0319,  0.0011,  0.0372]],\n       grad_fn=<SliceBackward0>) \n\nLayer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0404, -0.0308], grad_fn=<SliceBackward0>) \n\nLayer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0204, -0.0150, -0.0399,  ...,  0.0183, -0.0181,  0.0122],\n        [-0.0275, -0.0198,  0.0189,  ...,  0.0033,  0.0163, -0.0426]],\n       grad_fn=<SliceBackward0>) \n\nLayer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0353,  0.0435], grad_fn=<SliceBackward0>) \n")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"further-reading"},"Further Reading"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://pytorch.org/docs/stable/nn.html"},"torch.nn API"))))}c.isMDXComponent=!0}}]);