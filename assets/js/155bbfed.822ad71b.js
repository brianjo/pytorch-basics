"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[248],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>h});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function l(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?l(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},d=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},m=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),u=p(t),m=r,h=u["".concat(s,".").concat(m)]||u[m]||c[m]||l;return t?a.createElement(h,i(i({ref:n},d),{},{components:t})):a.createElement(h,i({ref:n},d))}));function h(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var l=t.length,i=new Array(l);i[0]=m;var o={};for(var s in n)hasOwnProperty.call(n,s)&&(o[s]=n[s]);o.originalType=e,o[u]="string"==typeof e?e:r,i[1]=o;for(var p=2;p<l;p++)i[p]=t[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},2137:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>c,frontMatter:()=>l,metadata:()=>o,toc:()=>p});var a=t(7462),r=(t(7294),t(3905));const l={},i=void 0,o={unversionedId:"BuildModel",id:"BuildModel",title:"BuildModel",description:"Learn the Basics ||",source:"@site/docs/06-BuildModel.md",sourceDirName:".",slug:"/BuildModel",permalink:"/pytorch-basics/docs/BuildModel",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/06-BuildModel.md",tags:[],version:"current",sidebarPosition:6,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Transforms",permalink:"/pytorch-basics/docs/Transforms"},next:{title:"Autograd",permalink:"/pytorch-basics/docs/Autograd"}},s={},p=[{value:"Get Device for Training",id:"get-device-for-training",level:2},{value:"Define the Class",id:"define-the-class",level:2},{value:"Model Layers",id:"model-layers",level:2},{value:"nn.Flatten",id:"nnflatten",level:3},{value:"nn.Linear",id:"nnlinear",level:3},{value:"nn.ReLU",id:"nnrelu",level:3},{value:"nn.Sequential",id:"nnsequential",level:3},{value:"nn.Softmax",id:"nnsoftmax",level:3},{value:"Model Parameters",id:"model-parameters",level:2},{value:"Further Reading",id:"further-reading",level:2}],d={toc:p},u="wrapper";function c(e){let{components:n,...t}=e;return(0,r.kt)(u,(0,a.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"intro.html"},"Learn the Basics")," ||\n",(0,r.kt)("a",{parentName:"p",href:"quickstart_tutorial.html"},"Quickstart")," ||\n",(0,r.kt)("a",{parentName:"p",href:"tensorqs_tutorial.html"},"Tensors")," ||\n",(0,r.kt)("a",{parentName:"p",href:"data_tutorial.html"},"Datasets & DataLoaders")," ||\n",(0,r.kt)("a",{parentName:"p",href:"transforms_tutorial.html"},"Transforms")," ||\n",(0,r.kt)("strong",{parentName:"p"},"Build Model")," ||\n",(0,r.kt)("a",{parentName:"p",href:"autogradqs_tutorial.html"},"Autograd")," ||\n",(0,r.kt)("a",{parentName:"p",href:"optimization_tutorial.html"},"Optimization")," ||\n",(0,r.kt)("a",{parentName:"p",href:"saveloadrun_tutorial.html"},"Save & Load Model")),(0,r.kt)("h1",{id:"build-the-neural-network"},"Build the Neural Network"),(0,r.kt)("p",null,"Neural networks comprise of layers/modules that perform operations on data.\nThe ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/nn.html"},"torch.nn")," namespace provides all the building blocks you need to\nbuild your own neural network. Every module in PyTorch subclasses the ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Module.html"},"nn.Module"),".\nA neural network is a module itself that consists of other modules (layers). This nested structure allows for\nbuilding and managing complex architectures easily."),(0,r.kt)("p",null,"In the following sections, we'll build a neural network to classify images in the FashionMNIST dataset."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"%matplotlib inline\n\nimport os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n")),(0,r.kt)("h2",{id:"get-device-for-training"},"Get Device for Training"),(0,r.kt)("p",null,"We want to be able to train our model on a hardware accelerator like the GPU,\nif it is available. Let's check to see if\n",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/notes/cuda.html"},"torch.cuda")," is available, else we\ncontinue to use the CPU."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'device = "cuda" if torch.cuda.is_available() else "cpu"\nprint(f"Using {device} device")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Using cpu device\n")),(0,r.kt)("h2",{id:"define-the-class"},"Define the Class"),(0,r.kt)("p",null,"We define our neural network by subclassing ",(0,r.kt)("inlineCode",{parentName:"p"},"nn.Module"),", and\ninitialize the neural network layers in ",(0,r.kt)("inlineCode",{parentName:"p"},"__init__"),". Every ",(0,r.kt)("inlineCode",{parentName:"p"},"nn.Module")," subclass implements\nthe operations on input data in the ",(0,r.kt)("inlineCode",{parentName:"p"},"forward")," method."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"class NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n")),(0,r.kt)("p",null,"We create an instance of ",(0,r.kt)("inlineCode",{parentName:"p"},"NeuralNetwork"),", and move it to the ",(0,r.kt)("inlineCode",{parentName:"p"},"device"),", and print\nits structure."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"model = NeuralNetwork().to(device)\nprint(model)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"NeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n")),(0,r.kt)("p",null,"To use the model, we pass it the input data. This executes the model's ",(0,r.kt)("inlineCode",{parentName:"p"},"forward"),",\nalong with some ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866"},"background operations"),".\nDo not call ",(0,r.kt)("inlineCode",{parentName:"p"},"model.forward()")," directly!"),(0,r.kt)("p",null,"Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output.\nWe get the prediction probabilities by passing it through an instance of the ",(0,r.kt)("inlineCode",{parentName:"p"},"nn.Softmax")," module."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'X = torch.rand(1, 28, 28, device=device)\nlogits = model(X)\npred_probab = nn.Softmax(dim=1)(logits)\ny_pred = pred_probab.argmax(1)\nprint(f"Predicted class: {y_pred}")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Predicted class: tensor([3])\n")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"model-layers"},"Model Layers"),(0,r.kt)("p",null,"Let's break down the layers in the FashionMNIST model. To illustrate it, we\nwill take a sample minibatch of 3 images of size 28x28 and see what happens to it as\nwe pass it through the network."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"input_image = torch.rand(3,28,28)\nprint(input_image.size())\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"torch.Size([3, 28, 28])\n")),(0,r.kt)("h3",{id:"nnflatten"},"nn.Flatten"),(0,r.kt)("p",null,"We initialize the ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html"},"nn.Flatten"),"\nlayer to convert each 2D 28x28 image into a contiguous array of 784 pixel values (\nthe minibatch dimension (at dim=0) is maintained)."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"flatten = nn.Flatten()\nflat_image = flatten(input_image)\nprint(flat_image.size())\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"torch.Size([3, 784])\n")),(0,r.kt)("h3",{id:"nnlinear"},"nn.Linear"),(0,r.kt)("p",null,"The ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"},"linear layer"),"\nis a module that applies a linear transformation on the input using its stored weights and biases."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"layer1 = nn.Linear(in_features=28*28, out_features=20)\nhidden1 = layer1(flat_image)\nprint(hidden1.size())\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"torch.Size([3, 20])\n")),(0,r.kt)("h3",{id:"nnrelu"},"nn.ReLU"),(0,r.kt)("p",null,"Non-linear activations are what create the complex mappings between the model's inputs and outputs.\nThey are applied after linear transformations to introduce ",(0,r.kt)("em",{parentName:"p"},"nonlinearity"),", helping neural networks\nlearn a wide variety of phenomena."),(0,r.kt)("p",null,"In this model, we use ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html"},"nn.ReLU")," between our\nlinear layers, but there's other activations to introduce non-linearity in your model."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'print(f"Before ReLU: {hidden1}\\n\\n")\nhidden1 = nn.ReLU()(hidden1)\nprint(f"After ReLU: {hidden1}")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Before ReLU: tensor([[-2.4690e-01,  5.2232e-01, -8.3729e-02, -5.9470e-02,  2.7752e-01,\n          4.3835e-01,  6.8780e-02, -7.8510e-01,  6.1263e-02,  2.7854e-01,\n          1.3083e-01, -6.8150e-01,  7.8850e-04,  2.3999e-01, -4.7431e-01,\n         -2.8111e-01, -1.9974e-01,  2.3609e-02, -8.0268e-02, -2.5705e-01],\n        [-2.1225e-01,  7.1340e-01, -2.3558e-01,  4.5877e-02, -8.6979e-03,\n          5.9012e-01,  1.8088e-02, -4.5647e-01,  1.1153e-01, -1.0593e-01,\n          1.4186e-01, -6.1248e-01,  6.3168e-01,  3.3532e-01, -6.0130e-02,\n         -4.7285e-01,  9.0875e-02,  1.3109e-01,  1.9149e-01, -1.6091e-01],\n        [-1.6112e-01,  8.0238e-01, -4.0212e-01,  2.5643e-01, -2.8412e-01,\n          5.1592e-01, -1.9616e-02, -5.7990e-01,  3.9941e-02, -6.2257e-03,\n          2.1573e-01, -5.0835e-01, -1.1193e-02,  9.3616e-02, -2.4022e-01,\n         -1.2488e-01,  5.8471e-02,  3.3009e-01,  1.3525e-01, -1.0417e-01]],\n       grad_fn=<AddmmBackward0>)\n\n\nAfter ReLU: tensor([[0.0000e+00, 5.2232e-01, 0.0000e+00, 0.0000e+00, 2.7752e-01, 4.3835e-01,\n         6.8780e-02, 0.0000e+00, 6.1263e-02, 2.7854e-01, 1.3083e-01, 0.0000e+00,\n         7.8850e-04, 2.3999e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3609e-02,\n         0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 7.1340e-01, 0.0000e+00, 4.5877e-02, 0.0000e+00, 5.9012e-01,\n         1.8088e-02, 0.0000e+00, 1.1153e-01, 0.0000e+00, 1.4186e-01, 0.0000e+00,\n         6.3168e-01, 3.3532e-01, 0.0000e+00, 0.0000e+00, 9.0875e-02, 1.3109e-01,\n         1.9149e-01, 0.0000e+00],\n        [0.0000e+00, 8.0238e-01, 0.0000e+00, 2.5643e-01, 0.0000e+00, 5.1592e-01,\n         0.0000e+00, 0.0000e+00, 3.9941e-02, 0.0000e+00, 2.1573e-01, 0.0000e+00,\n         0.0000e+00, 9.3616e-02, 0.0000e+00, 0.0000e+00, 5.8471e-02, 3.3009e-01,\n         1.3525e-01, 0.0000e+00]], grad_fn=<ReluBackward0>)\n")),(0,r.kt)("h3",{id:"nnsequential"},"nn.Sequential"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html"},"nn.Sequential")," is an ordered\ncontainer of modules. The data is passed through all the modules in the same order as defined. You can use\nsequential containers to put together a quick network like ",(0,r.kt)("inlineCode",{parentName:"p"},"seq_modules"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"seq_modules = nn.Sequential(\n    flatten,\n    layer1,\n    nn.ReLU(),\n    nn.Linear(20, 10)\n)\ninput_image = torch.rand(3,28,28)\nlogits = seq_modules(input_image)\n")),(0,r.kt)("h3",{id:"nnsoftmax"},"nn.Softmax"),(0,r.kt)("p",null,"The last linear layer of the neural network returns ",(0,r.kt)("inlineCode",{parentName:"p"},"logits")," - raw values in ","[-\\infty, \\infty]"," - which are passed to the\n",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html"},"nn.Softmax")," module. The logits are scaled to values\n","[0, 1]"," representing the model's predicted probabilities for each class. ",(0,r.kt)("inlineCode",{parentName:"p"},"dim")," parameter indicates the dimension along\nwhich the values must sum to 1."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"softmax = nn.Softmax(dim=1)\npred_probab = softmax(logits)\n")),(0,r.kt)("h2",{id:"model-parameters"},"Model Parameters"),(0,r.kt)("p",null,"Many layers inside a neural network are ",(0,r.kt)("em",{parentName:"p"},"parameterized"),", i.e. have associated weights\nand biases that are optimized during training. Subclassing ",(0,r.kt)("inlineCode",{parentName:"p"},"nn.Module")," automatically\ntracks all fields defined inside your model object, and makes all parameters\naccessible using your model's ",(0,r.kt)("inlineCode",{parentName:"p"},"parameters()")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"named_parameters()")," methods."),(0,r.kt)("p",null,"In this example, we iterate over each parameter, and print its size and a preview of its values."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'print(f"Model structure: {model}\\n\\n")\n\nfor name, param in model.named_parameters():\n    print(f"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Model structure: NeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n\n\nLayer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0284, -0.0247, -0.0045,  ...,  0.0112,  0.0189, -0.0118],\n        [ 0.0130,  0.0269, -0.0259,  ...,  0.0340,  0.0330, -0.0258]],\n       grad_fn=<SliceBackward0>) \n\nLayer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0105, 0.0007], grad_fn=<SliceBackward0>) \n\nLayer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0345, -0.0161, -0.0066,  ...,  0.0229, -0.0357, -0.0119],\n        [ 0.0166, -0.0344,  0.0432,  ..., -0.0193, -0.0421, -0.0376]],\n       grad_fn=<SliceBackward0>) \n\nLayer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0267,  0.0018], grad_fn=<SliceBackward0>) \n\nLayer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0156,  0.0423, -0.0397,  ..., -0.0084, -0.0412,  0.0401],\n        [ 0.0087,  0.0331, -0.0115,  ..., -0.0276, -0.0353,  0.0136]],\n       grad_fn=<SliceBackward0>) \n\nLayer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0130, -0.0076], grad_fn=<SliceBackward0>) \n")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"further-reading"},"Further Reading"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://pytorch.org/docs/stable/nn.html"},"torch.nn API"))))}c.isMDXComponent=!0}}]);